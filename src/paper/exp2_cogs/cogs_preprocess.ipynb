{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-15T09:38:49.970827Z",
     "start_time": "2025-02-15T09:38:49.954567Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 2,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T09:38:49.984213Z",
     "start_time": "2025-02-15T09:38:49.974176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# - dataset -> read in\n",
    "# select constructions\n",
    "# run code using idioms to identify the word spans\n",
    "# get scores\n",
    "# plot as boxplots?"
   ],
   "id": "486e7fe22cdab4c0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T09:38:55.751227Z",
     "start_time": "2025-02-15T09:38:55.725329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Read in original cogs dataset\n",
    "\"\"\"\n",
    "from data_config import Exp2Cogs\n",
    "import pandas as pd\n",
    "from typing import Dict, List\n",
    "\n",
    "def read_csv_by_column(file_path: str) -> Dict[str, List]:\n",
    "    \"\"\"Reads a CSV file and returns a dictionary where keys are column names\n",
    "    and values are lists of column data.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List]: Dictionary containing column-wise data.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df.to_dict(orient=\"list\")\n",
    "\n",
    "# Example usage\n",
    "csv_data = read_csv_by_column(Exp2Cogs.original_csv)"
   ],
   "id": "fe79fff6e160fb78",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T09:38:55.775941Z",
     "start_time": "2025-02-15T09:38:55.755494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Process part 1 - get data into another csv for manual review\n",
    "# filter parenthetical\n",
    "# check num periods\n",
    "# check that the words are present\n",
    "# remove bad rows\n",
    "\"\"\"\n",
    "from typing import Set, Tuple\n",
    "\n",
    "from dataclasses import dataclass, field, asdict\n",
    "\n",
    "@dataclass\n",
    "class DataRow:\n",
    "    cx_type: str = field(init=False)\n",
    "    sentence: str = field(init=False)\n",
    "    sentence_with_idxs: List[Tuple[int, str]] = field(init=False)\n",
    "    tgt_words: List[int] = field(init=False)\n",
    "    errors: List[str] = field(default_factory=list)\n",
    "\n",
    "\n",
    "def count_symbols(s: str, symbols: List[str]) -> Dict[str, int]:\n",
    "    \"\"\"Counts occurrences of specified symbols in a string.\n",
    "\n",
    "    Args:\n",
    "        s (str): The input string.\n",
    "        symbols (Set[str]): A set of symbols to count.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, int]: A dictionary mapping each symbol to its count in the string.\n",
    "    \"\"\"\n",
    "    symbols = set(symbols)\n",
    "    ct = 0\n",
    "    for sym in symbols:\n",
    "        ct += s.count(sym)\n",
    "    return ct\n",
    "\n",
    "def get_end_of_str_by_punct(s: str):\n",
    "    for sym in ['.', '!', '?']:\n",
    "        idx = s.find(sym)\n",
    "        if idx != -1: break\n",
    "\n",
    "    return idx\n",
    "\n",
    "def clean_data_list(data_list: List[str], cx_type: str, tgt_words: str) -> List[DataRow]:\n",
    "    ret_list: List[DataRow] = []\n",
    "    for s in data_list:\n",
    "        # make sure valid string (some are weird or nans)\n",
    "        if not isinstance(s, str):\n",
    "            continue\n",
    "        if len(s) < 4:\n",
    "            continue\n",
    "\n",
    "        # accrue info\n",
    "        dr = DataRow()\n",
    "        ret_list.append(dr)\n",
    "        dr.cx_type = cx_type\n",
    "        dr.sentence_with_idxs = [(idx, w) for idx, w in enumerate(s.split(\" \"))]\n",
    "\n",
    "        if count_symbols(s, ['.', '!', '?']) != 1:\n",
    "            dr.errors.append(\"no punct\")\n",
    "            dr.sentence = s\n",
    "        else:\n",
    "            idx = get_end_of_str_by_punct(s)\n",
    "            truncated_str = s[:idx + 1]\n",
    "            dr.sentence = truncated_str\n",
    "\n",
    "        dr.tgt_words = []\n",
    "        tgts = tgt_words.split(\" \")\n",
    "        for t in tgts:\n",
    "            t_idxs = [idx for (idx, w) in dr.sentence_with_idxs if w.lower() == t.lower()]\n",
    "            dr.tgt_words.extend(t_idxs)\n",
    "            if s.lower().count(t) != 1:\n",
    "                dr.errors.append(\"tgt word ct != 1\")\n",
    "    return ret_list\n",
    "\n",
    "def write_data_rows_to_csv(rows: List[DataRow], file_path: str) -> None:\n",
    "    \"\"\"Writes a list of DataRow instances to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        rows (List[DataRow]): The list of DataRow instances.\n",
    "        file_path (str): Path to save the CSV file.\n",
    "    \"\"\"\n",
    "    # Convert dataclass instances to dictionaries\n",
    "    data_dicts = [asdict(row) for row in rows]\n",
    "\n",
    "    # Convert list fields to string for CSV storage\n",
    "    for data in data_dicts:\n",
    "        data[\"sentence_with_idxs\"] = str(data[\"sentence_with_idxs\"])\n",
    "        data[\"tgt_words\"] = str(data[\"tgt_words\"])\n",
    "        data[\"errors\"] = \", \".join(data[\"errors\"])  # Join error messages for readability\n",
    "\n",
    "    # Convert to DataFrame and save to CSV\n",
    "    df = pd.DataFrame(data_dicts)\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n"
   ],
   "id": "118aa48fd6879a9b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T09:38:55.797697Z",
     "start_time": "2025-02-15T09:38:55.780811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(csv_data.keys())\n"
   ],
   "id": "6bbd387462b5afe1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Let Alone', 'Way Manner', 'Resultative', 'Conative', 'Intransitive Motion', 'Caused Motion', 'Causative with CxN', 'Ditransitive CxN', 'Comparative Correlative ', 'Unnamed: 9', 'Much Less ', 'Unnamed: 11', 'Unnamed: 12'])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T09:38:55.828705Z",
     "start_time": "2025-02-15T09:38:55.801714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "tgt_keys_str_map = {\n",
    "    'Let Alone': 'let alone',\n",
    "    'Way Manner': 'way',\n",
    "    'Conative': 'at',\n",
    "    'Comparative Correlative ': 'the',\n",
    "    'Much Less ': 'much less',\n",
    "    'Causative with CxN': 'with'\n",
    "}\n",
    "def get_all_data():\n",
    "    all_data: List[DataRow] = []\n",
    "    for k, words in tgt_keys_str_map.items():\n",
    "        unclean_data = csv_data[k]\n",
    "        clean_data = clean_data_list(unclean_data, k, words)\n",
    "        all_data.extend(clean_data)\n",
    "    return all_data\n",
    "\n",
    "all_data = get_all_data()\n",
    "\n",
    "# uncomment to reproduce\n",
    "# write_data_rows_to_csv(all_data, Exp2Cogs.cogs_parsed)\n"
   ],
   "id": "c9a579d8e3cbe271",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T09:38:55.851031Z",
     "start_time": "2025-02-15T09:38:55.832360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "we manually processed data by hand in google sheets where there were errors\n",
    "\"\"\""
   ],
   "id": "604faa1fe3cad32d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwe manually processed data by hand in google sheets where there were errors\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T09:38:56.183428Z",
     "start_time": "2025-02-15T09:38:55.855212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from paper.exp2_cogs.cogs_utils import read_csv_row_by_row, get_all_data_clean\n",
    "\n",
    "\"\"\"\n",
    "Read in final dataset + verify\n",
    "\"\"\"\n",
    "\n",
    "csv_data_clean = read_csv_row_by_row(Exp2Cogs.cogs_parsed_final)\n",
    "print(csv_data_clean[0])\n"
   ],
   "id": "7389a1a9a53b522c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Let Alone', 'Most wives are too bloody old, let alone mothers.', '[6, 7]', \"[(0, 'Most'), (1, 'wives'), (2, 'are'), (3, 'too'), (4, 'bloody'), (5, 'old,'), (6, 'let'), (7, 'alone'), (8, 'mothers.'), (9, '(FN'), (10, 'Construction)')]\", '']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T09:38:56.208986Z",
     "start_time": "2025-02-15T09:38:56.188522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "all_cogs_clean = get_all_data_clean(csv_data_clean)\n",
    "# all_clean[0]"
   ],
   "id": "d0cdbe91a438aa72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in sent Though punctuated by frequent flash-backs to the period before, during and just after the war, temporal progression in the present is clearly marked by the development of two narrative lines which weave their ways in and out of the novel., idx 33 != way\n",
      "note expected one error message bc one word is 'ways' instead of 'way'\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T09:38:56.233718Z",
     "start_time": "2025-02-15T09:38:56.213526Z"
    }
   },
   "cell_type": "code",
   "source": "all_cogs_clean[0]",
   "id": "fbf68f59624e1302",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CogsEntry(id=0, cx_type='Let Alone', sent='Most wives are too bloody old, let alone mothers.', tgt_words=[6, 7], tgt_word_offsets=[(31, 34), (35, 40)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
