{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T03:36:29.485789Z",
     "start_time": "2025-09-19T03:36:29.472720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\"\"\"\n",
    "Same behavior as corr_matrix.ipynb, but in particular for the plots for latex\n",
    "\"\"\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ],
   "id": "377476e593a79cd6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T03:36:30.195488Z",
     "start_time": "2025-09-19T03:36:30.028012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lib.common.mlm_singleton import init_singleton_scorer\n",
    "from lib.distr_diff_fcns import jensen_shannon_divergence\n",
    "import os\n",
    "from make_graphics.graphics import make_fig_saver, Colors\n",
    "\n",
    "fig_saver = make_fig_saver()\n",
    "\n",
    "# make sure we init the scorer for all modules first\n",
    "mlm_scorer = init_singleton_scorer('roberta-large', output_attentions=True)\n",
    "\n",
    "# make the warnings shut up (likely bc of latex call)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ],
   "id": "6b47557bbd3d5ed5",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lib'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmlm_singleton\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m init_singleton_scorer\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistr_diff_fcns\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m jensen_shannon_divergence\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'lib'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "from rozlib.libs.plotting.plotting import add_rect_to_grid, add_bottom_edge_to_grid, add_edges_to_grid\n",
    "from lib.scoring_fns import surprisal\n",
    "from lib.exp_common.corr_matrix import get_scores\n",
    "from lib.plotting.plot_corr_matrix import plot_heatmap\n",
    "from rozlib.libs.plotting.utils_latex_matplot import config_matplot_for_latex, save_fig\n",
    "\n"
   ],
   "id": "b85f5b1b393e6492"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from lib.plotting.plots import plot_all_affinities, plot_multiple_global_aff, plot_one_global_aff\n",
    "\n",
    "\"\"\"Green day examples\"\"\"\n",
    "s1 = \"My favorite is Green Day.\"\n",
    "s2 = \"My favorite band is Green Day.\"\n",
    "\n",
    "# use save_fig to save these\n",
    "gaf1 = plot_all_affinities(s1, do_make_local_aff_heatmap=False)\n",
    "# add a placeholder 0 to align them (band)\n",
    "gaf1.insert(2, 0)\n",
    "gaf2 = plot_all_affinities(s2, do_make_local_aff_heatmap=False)\n"
   ],
   "id": "e0e8de5d1c2f5ff0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from lib.plotting.plots import plot_multiple_global_aff\n",
    "\n",
    "both = [gaf1, gaf2]\n",
    "\n",
    "config_matplot_for_latex(14)\n",
    "\n",
    "all_words = s2.strip(\".\").split(\" \")\n",
    "words_1 = all_words.copy()\n",
    "print(words_1)\n",
    "# words_1[2] = (r\"\\dots .\")\n",
    "words_1[2] = (r\" \")\n",
    "\n",
    "# can plot individually\n",
    "# plot_new([gaf1], words_1)\n",
    "# plot_new([gaf2], all_words)\n",
    "\n",
    "fig = plot_multiple_global_aff(\n",
    "    [\n",
    "        (gaf1, words_1),\n",
    "        (gaf2, all_words),\n",
    "    ],\n",
    "    overall_fig_size=(3,3),\n",
    "    x_locs=[[2], []]\n",
    ")\n",
    "# save_fig(fig, \"gaf_green_day_band.pdf\")\n",
    "fig_saver.save(fig, \"fig7_gaf_green_day_band.pdf\")\n",
    "\n"
   ],
   "id": "9e85ce29520e543a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"plots for kick the bucket examples\"\"\"\n",
    "\n",
    "config_matplot_for_latex(12, )\n",
    "\n",
    "s1 = \"The old man kicked the bucket.\"\n",
    "s2 = \"The old man finally kicked the bucket.\"\n",
    "s3 = \"The old man finally kicked the bucket and the funeral is tomorrow.\"\n",
    "\n",
    "tgt_length_per_square = 0.6\n",
    "\n",
    "words_1 = s1.strip(\".\").split(\" \")\n",
    "# words_1.insert(3, r\"\\dots.\")\n",
    "words_1.insert(3, r\" \")\n",
    "# words_1.extend([\"\"]*5)\n",
    "words_2 = s2.strip(\".\").split(\" \")\n",
    "# words_2.extend([\"\"]*5)\n",
    "words_3 = s3.strip(\".\").split(\" \")\n",
    "\n",
    "# use save_fig to save these\n",
    "# print(gaf1)\n",
    "# print(words_1)\n",
    "gaf1 = plot_all_affinities(\n",
    "    s1,\n",
    "    do_make_local_aff_heatmap=False,\n",
    "    # output_file_for_global_aff=\"kick1.png\"\n",
    ")\n",
    "gaf1.insert(3, 0)   # for band\n",
    "gaf1.extend([0]*5)\n",
    "words_1.extend([\"---\"]*5)\n",
    "words_2.extend([\"---\"]*5)\n",
    "gaf2 = plot_all_affinities(\n",
    "    s2,\n",
    "    do_make_local_aff_heatmap=False,\n",
    "    # output_file_for_global_aff=\"kick2.png\"\n",
    ")\n",
    "gaf2.extend([0]*5)\n",
    "\n",
    "gaf3 = plot_all_affinities(\n",
    "    s3,\n",
    "    do_make_local_aff_heatmap=False,\n",
    "    # output_file_for_global_aff=\"kick3.png\"\n",
    ")\n",
    "\n",
    "x_locs = [\n",
    "    [3] + list(range(7,12)),\n",
    "    list(range(7,12)),\n",
    "    []\n",
    "]\n",
    "\n",
    "fig = plot_multiple_global_aff([\n",
    "    (gaf1, words_1),\n",
    "    (gaf2, words_2),\n",
    "    (gaf3, words_3)\n",
    "],\n",
    "    overall_fig_size=(5,3),\n",
    "    x_locs=x_locs\n",
    ")\n",
    "fig_saver.save(fig, \"kick_the_bucket_new_gray.pdf\")\n",
    "# save_fig(fig, \"kick_the_bucket_new_gray.pdf\")\n",
    "\n"
   ],
   "id": "a703f413c04fbcb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_sorted_idxs_for_matrix(m: List[List[float]]):\n",
    "    one_d_list = []\n",
    "    for row in m:\n",
    "        one_d_list.extend(row)\n",
    "    assert len(one_d_list) == len(m)**2\n",
    "\n",
    "    one_d_list_with_values = [(i, v) for i,v in enumerate(one_d_list)]\n",
    "    one_d_list_with_values.sort(key= lambda x: x[1])\n",
    "    return [x[0] for x in one_d_list_with_values]\n",
    "\n"
   ],
   "id": "fff637403c158d0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from pprint import pp\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "## Produce fig 1b - the so-that plot with two red rectangles to show aap vs cec that\n",
    "\n",
    "\n",
    "# def get_color():\n",
    "#     cmap = plt.cm.Dark2\n",
    "#\n",
    "#     return cmap(3)\n",
    "\n",
    "# todo: note that this code is partially duplicating plot_all_affinities\n",
    "def make_so_that_plot(\n",
    "        add_rects = True,\n",
    "        file_type = \"pdf\"\n",
    "):\n",
    "    sent = \"I was so excited that I saw you that I told my Mom.\"\n",
    "\n",
    "    sent_word_list = sent.strip(\".\").split(\" \")\n",
    "    subbed_word_list = sent_word_list.copy()\n",
    "    # subbed_word_list[2] = \"so (cec)\"\n",
    "    # subbed_word_list[4] = r\"that (aap)\"\n",
    "    # subbed_word_list[8] = \"that (cec)\"\n",
    "\n",
    "    subbed_word_list[2] = r\"\\textbf{so}\"\n",
    "    subbed_word_list[4] = r\"\\textbf{that$_1$}\"\n",
    "    subbed_word_list[8] = r\"\\textbf{that$_2$}\"\n",
    "\n",
    "    print(sent_word_list)\n",
    "    print(subbed_word_list)\n",
    "    print(len(subbed_word_list))\n",
    "\n",
    "    scores, new_sents, multi_tok_indices, sent_word_list, hhis, preds, probs, actual_subs = get_scores(\n",
    "        sent,\n",
    "        subs_list = None,\n",
    "        subs_method=\"mask\",\n",
    "        score_fn = surprisal ,\n",
    "        num_preds=2,\n",
    "        dist_diff_fn=jensen_shannon_divergence\n",
    "    )\n",
    "    # if you want to see orders of magnitude diff\n",
    "    pp(torch.round(scores, decimals=2))\n",
    "    fig = plot_heatmap(scores,\n",
    "                       subbed_word_list,\n",
    "                       # actual_subs,\n",
    "                       ylabels=None,\n",
    "                       cmap=\"Greys\",\n",
    "                       title=None,\n",
    "                       add_colorbar=False,\n",
    "                       fig_size=(3,3),\n",
    "                       return_fig=True,\n",
    "                       xlabel_rotation=45,\n",
    "                       vmin_max=(0.0, 0.69)\n",
    "                       )\n",
    "\n",
    "    # red rectangle annotations on top\n",
    "    rect_color = Colors.rectangle_color\n",
    "    ax = fig.axes[0]\n",
    "\n",
    "    fname = \"cec_so_that_affinity.\" + file_type\n",
    "    if add_rects:\n",
    "        # add_rect_to_grid(ax, len(sent_word_list), 2, 4, 1, 1, rect_color)\n",
    "        # add_rect_to_grid(ax, len(sent_word_list), 2, 8, 1, 1, rect_color)\n",
    "        # add_bottom_edge_to_grid(ax, len(sent_word_list), 2, 4, 1, 1, rect_color)\n",
    "        # add_bottom_edge_to_grid(ax, len(sent_word_list), 2, 8, 1, 1, rect_color)\n",
    "        add_edges_to_grid(ax, len(sent_word_list), 2, 4, 1, 1, rect_color)\n",
    "        add_edges_to_grid(ax, len(sent_word_list), 2, 8, 1, 1, rect_color)\n",
    "\n",
    "        fname = \"cec_so_that_affinity_no_rect.\" + file_type\n",
    "\n",
    "    ax.grid(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # save_fig(fig, Path(\".\"), fname)\n",
    "    return fig, scores\n",
    "\n",
    "    return scores\n",
    "\n",
    "config_matplot_for_latex(14, dpi=150)\n",
    "\n",
    "# uncomment to produce plot\n",
    "fig, s2 = make_so_that_plot(\n",
    "    add_rects=True,\n",
    "    file_type=\"png\"\n",
    ")\n",
    "pp(s2)"
   ],
   "id": "ae638f73d7f5777e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bb546dd25ad6b2f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d4e1b747a109f095"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9b96d773bcc90701"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "80ba7c17b29bd19a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aaf7e81ff0d379a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9a44d40f67c47c53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# todo: duplicates above, only rewrites the sentence and the labeling\n",
    "def make_so_that_plot_leonie(\n",
    "        add_rects = True,\n",
    "        file_type = \"pdf\"\n",
    "):\n",
    "    ###### this is the only part that is diff\n",
    "    sent = \"I was so happy that I cried.\"\n",
    "    sent_word_list = sent.strip(\".\").split(\" \")\n",
    "    subbed_word_list = sent_word_list.copy()\n",
    "    subbed_word_list[2] = r\"\\textbf{so}\"\n",
    "    subbed_word_list[-3] = r\"\\textbf{that}\"\n",
    "    # subbed_word_list[7] = r\"\\textbf{that$_2$}\"\n",
    "    ###\n",
    "    # end diff\n",
    "\n",
    "    print(sent_word_list)\n",
    "    print(subbed_word_list)\n",
    "    print(len(subbed_word_list))\n",
    "\n",
    "    scores, new_sents, multi_tok_indices, sent_word_list, hhis, preds, probs, actual_subs = get_scores(\n",
    "        sent,\n",
    "        subs_list = None,\n",
    "        subs_method=\"mask\",\n",
    "        score_fn = surprisal ,\n",
    "        num_preds=2,\n",
    "        dist_diff_fn=jensen_shannon_divergence\n",
    "    )\n",
    "    # if you want to see orders of magnitude diff\n",
    "    pp(torch.round(scores, decimals=2))\n",
    "    fig = plot_heatmap(scores,\n",
    "                       subbed_word_list,\n",
    "                       # actual_subs,\n",
    "                       ylabels=None,\n",
    "                       cmap=\"Greys\",\n",
    "                       title=None,\n",
    "                       add_colorbar=False,\n",
    "                       fig_size=(3,3),\n",
    "                       return_fig=True,\n",
    "                       xlabel_rotation=45\n",
    "                       )\n",
    "\n",
    "    # red rectangle annotations on top\n",
    "    rect_color = get_color()\n",
    "    ax = fig.axes[0]\n",
    "\n",
    "    fname = \"cec_so_that_affinity.\" + file_type\n",
    "    if add_rects:\n",
    "        add_rect_to_grid(ax, len(sent_word_list), 2, 4, 1, 1, rect_color)\n",
    "        add_rect_to_grid(ax, len(sent_word_list), 2, 8, 1, 1, rect_color)\n",
    "        fname = \"cec_so_that_affinity_no_rect.\" + file_type\n",
    "\n",
    "    ax.grid(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    save_fig(fig, Path(\".\"), fname)\n",
    "\n",
    "    return scores\n",
    "\n",
    "config_matplot_for_latex(14, dpi=300)\n",
    "\n",
    "# uncomment to produce plot\n",
    "s2 = make_so_that_plot_leonie(\n",
    "    add_rects=False,\n",
    "    file_type=\"pdf\"\n",
    ")\n"
   ],
   "id": "72c87da16c211c0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# JSD and euclidean are not monotonic and thus cannot be used interchangeably\n",
    "# s1_sorted = get_sorted_idxs_for_matrix(s1)\n",
    "# s2_sorted = get_sorted_idxs_for_matrix(s2)\n",
    "# print(s1_sorted)\n",
    "# print(s2_sorted)\n"
   ],
   "id": "b0ced9d12c6f8dea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# green day examples\n",
    "1. (todo) fig 4 - My favorite is green day vs My favorite band is green day -ยก\n",
    "    - make smaller (move the word labels below the squares, only scores inside the squares)\n",
    "1. fig 5 - aff matrix - My favorite band is Green Day.\n",
    "2. fig 6 - aff matrix - I saw my favorite band reen day in concert\n",
    "\n",
    "## notes\n",
    "- note that fig 8 in the appendix (heat map for eap/aap) is produced in scoring/exp5_aap_eap_cec/exp5_extract_umap.ipynb (toward bottom)\n"
   ],
   "id": "4d1d28356aa0b534"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# fig 4\n",
    "\"\"\"Green day examples\"\"\"\n",
    "s1 = \"My favorite is Green Day.\"\n",
    "s2 = \"My favorite band is Green Day.\"\n",
    "\n",
    "# use save_fig to save these\n",
    "plot_all_affinities(s1, do_make_local_aff_heatmap=False)\n",
    "plot_all_affinities(s2, do_make_local_aff_heatmap=False)\n",
    "\n",
    "None    # suppress output\n",
    "\n"
   ],
   "id": "7d59421564ed3e4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# use 14 and fig size (3,3) in plot_heatmap to get the same sizing as others for the multifigure\n",
    "config_matplot_for_latex(14)\n",
    "\n",
    "def make_green_day_plot(sent: str,\n",
    "                        filename: str,\n",
    "                        figsize=(3,3)\n",
    "                        ):\n",
    "    sent_word_list = sent.strip(\".\").split(\" \")\n",
    "    # print(sent_word_list)\n",
    "\n",
    "    scores, new_sents, multi_tok_indices, sent_word_list, hhis, preds, probs, actual_subs = get_scores(\n",
    "        sent,\n",
    "        subs_list = None,\n",
    "        subs_method=\"mask\",\n",
    "        score_fn = surprisal ,\n",
    "        num_preds=2,\n",
    "        dist_diff_fn=jensen_shannon_divergence\n",
    "    )\n",
    "    fig = plot_heatmap(scores,\n",
    "                       sent_word_list,\n",
    "                       # actual_subs,\n",
    "                       ylabels=None,    # no right hand y axis labels\n",
    "                       # cmap=\"Blues\",\n",
    "                       cmap=\"Grays\",\n",
    "                       title=None,\n",
    "                       add_colorbar=False,\n",
    "                       fig_size=figsize,\n",
    "                       return_fig=True,\n",
    "                       xlabel_rotation=45\n",
    "                       )\n",
    "    return fig\n",
    "\n",
    "\n"
   ],
   "id": "6b909578eaea8a39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# fig 5\n",
    "\n",
    "config_matplot_for_latex(14)\n",
    "s = \"My favorite band is Green Day.\"\n",
    "sent_word_list = s.strip(\".\").split(\" \")\n",
    "fname = \"aff_green_fave_band_is.pdf\"\n",
    "fig = make_green_day_plot(\"My favorite band is Green Day.\",fname)\n",
    "\n",
    "\n",
    "ax = fig.axes[0]\n",
    "ax.grid(False)\n",
    "add_rect_to_grid(ax, len(sent_word_list), 2, 0, 1, 2, get_color(), linewidth=2.5)\n",
    "add_rect_to_grid(ax, len(sent_word_list), 4, 3, 2, 1, get_color(), linewidth=2.5)\n",
    "save_fig(fig, fname)\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "b661f6b00fc21b0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# fig 6\n",
    "# commas are passed to model but are not plotted\n",
    "config_matplot_for_latex(14)\n",
    "\n",
    "s = \"I saw my favorite band, Green Day, in concert.\"\n",
    "fname = \"aff_green_band_concert.pdf\"\n",
    "sent_word_list = s.strip(\".\").split(\" \")\n",
    "fig = make_green_day_plot(s, fname)\n",
    "\n",
    "ax = fig.axes[0]\n",
    "ax.grid(False)\n",
    "add_rect_to_grid(ax, len(sent_word_list), 4, 2, 1, 2, get_color(), linewidth=2)\n",
    "add_rect_to_grid(ax, len(sent_word_list), 5, 4, 2, 1, get_color(), linewidth=2)\n",
    "# save_fig(fig, fname)\n",
    "\n"
   ],
   "id": "3a4a6337d594bb49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# appendix fig 10\n",
    "\n",
    "config_matplot_for_latex(14)\n",
    "make_green_day_plot(\"My favorite is Green Day.\", \"aff_greenday_no_context.pdf\")\n",
    "\n",
    "# note appendix fig 11 is the same as fig 5\n",
    "\n",
    "None\n"
   ],
   "id": "3a60d2919879fae8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from rozlib.libs.plotting.plotting import print_color_map_with_hex\n",
    "\n",
    "# Choose a colormap (e.g., 'Dark2')\n",
    "cmap = plt.cm.Dark2\n",
    "\n",
    "# get color map for use with external softwares\n",
    "print_color_map_with_hex(cmap)\n",
    "\n"
   ],
   "id": "36d149f98788e1cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "config_matplot_for_latex(14, dpi=1000)      # higher for leonie with png\n",
    "# make_green_day_plot(\"Alice went to the hardware store and she bought a hammer.\", \"aff_matrix_alice_hammer.pdf\")\n",
    "# make_green_day_plot(\"Alice went to the hardware store and she bought a hammer.\", \"aff_matrix_alice_hammer_33_.png\", (3,3))\n",
    "\n",
    "None\n",
    "\n"
   ],
   "id": "ed42a102fcc88eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "s = \"Alice went to the hardware store and she bought a hammer.\"\n",
    "words = s.strip(\".\").split(\" \")\n",
    "\n",
    "# use save_fig to save these\n",
    "gaf1 = plot_all_affinities(s, do_make_local_aff_heatmap=False)\n",
    "\n"
   ],
   "id": "68f8f0be4e2ebf75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(len(gaf1))\n",
    "print([round(x,2) for x in gaf1])\n",
    "print(len(words))\n",
    "fig = plot_one_global_aff(\n",
    "    gaf1,\n",
    "    words,\n",
    "    figsize_if_plotting_single=(4,2)\n",
    ")\n",
    "save_fig(fig, \"gaf_alice_hammer.pdf\")"
   ],
   "id": "3595d6aafbae69d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Not reviewed (old)"
   ],
   "id": "ea46470071ebb016"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "# sent = \"I was so excited that I saw you that I told my Mom.\"\n",
    "# sent_word_list = sent.strip(\".\").split(\" \")\n",
    "# subbed_word_list = sent_word_list.copy()\n",
    "# # subbed_word_list[2] = \"so (cec)\"\n",
    "# subbed_word_list[4] = \"that (aap)\"\n",
    "# subbed_word_list[8] = \"that (cec)\"\n",
    "#\n",
    "# print(sent_word_list)\n",
    "# print(subbed_word_list)\n",
    "# print(len(subbed_word_list))\n",
    "#\n",
    "# scores, new_sents, multi_tok_indices, sent_word_list, hhis, preds, probs, actual_subs = get_scores(\n",
    "#     sent,\n",
    "#     subs_list = None,\n",
    "#     subs_method=\"mask\",\n",
    "#     score_fn = surprisal ,\n",
    "#     num_preds=2,\n",
    "#     dist_diff_fn=jensen_shannon_divergence\n",
    "# )\n",
    "\n",
    "\n"
   ],
   "id": "26773229c164aa1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# s = \"Dana is an Australian paralympic swimmer. She was born in the Queensland town of St. George.\"\n",
    "s = \"Dana is an Australian paralympic swimmer.\"\n",
    "# s = \"Her early results led to her being offered one of the first Australian Institute of Sport scholarships for disabled swimmers.\"\n",
    "# s = \"I heard Red Day recently.\"\n",
    "# s = \"Green Day is a band I heard recently.\"\n",
    "s = \"My favorite band that I heard recently in concert is Green Day. They are really good.\"\n",
    "s = \"I was so sad that you cried.\"\n",
    "s = \"From now on 'BO' means 'so'. Whereever 'so' o\n",
    "plot_all_affinities(s, do_make_local_aff_heatmap=False)\n"
   ],
   "id": "2ba786cb768df285"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "plot_all_affinities(s2, use_euclid=True)"
   ],
   "id": "942bbf7f8049a5db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "orig_sent = \" i was so happy that i saw you that i told my mom.\"\n",
    "orig_sent = \" i went to the farm and got an apple.\"\n",
    "orig_sent = \" i am so sad that i might cry.\"\n",
    "orig_sent = \" he saw a horse at the farm.\"\n",
    "orig_sent = \" a dog is my favorite animal.\"\n",
    "orig_sent = \"I was so happy that I saw you that I told my mom.\"\n",
    "orig_sent = \"It was so big that it fell over.\"\n",
    "orig_sent = \"I was so sad that it fell over.\"\n",
    "orig_sent = \"This task was very easy, a piece of cake.\".lower()\n",
    "orig_sent = \"My favorite band is Green Day.\"\n",
    "orig_sent = \"Surprisingly, in Burma, the belief was once so widespread that the Sumatran rhino ate fire.\"\n",
    "orig_sent = \"For example, Zhu Youliang the Prince of Heng, an older cousin of the emperor's, was so honored at court at that time that even Li Yu's superior, the chief of staff Li Zhen, kneeled to him.\"\n",
    "# orig_sent = \"It has also been noted that he was so satisfied that he did this without fee or reward and was publicly thanked.\"\n",
    "orig_sent = \"He was so satisfied that he gave the speech without fee or reward and was publicly thanked.\"\n",
    "orig_sent = 'The judges were all so surprised that one of them had a \"spasm,\" one leaned against the wall for support, and the other fell backwards into a barrel of flour!'\n",
    "orig_sent = 'I did not want to, but a friend was so adamant that I tried it.'\n",
    "orig_sent = 'There are a couple of false notes along the way, such as a dreadful rendition in front of a room of people of \"Youre So Vain,\" but so many moments are so right that I had no trouble forgiving them the few missteps.'\n",
    "orig_sent = \"By 1844, he was so accomplished that his father gathered together as much money as he could (apparently even selling the family piano) and sent him to study in Rome at the Accademia di San Luca.\"\n",
    "plot_all_affinities(orig_sent, None, use_euclid=False, use_probability=True)\n",
    "\n"
   ],
   "id": "a9804b304e414737"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "25d0b0c5778d9108"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_all_affinities(s2, use_euclid=True)\n",
   "id": "b34561f10fa44396"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "s3 = \"I saw my favorite band, Green Day, in concert.\"\n",
    "plot_all_affinities(s3)\n"
   ],
   "id": "c11e1798923bf36b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5d2da74ff2d333b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## not for latex, just experiments\n",
    "s3 = \"Plate by <mask> the chef improved his cooking, and each <mask> was better than the last.\"\n",
    "s3 = \"Soup by <mask> the chef improved his cooking, and each <mask> was better than the last.\"\n",
    "s3 = \"Grain by grain the chef improved his cooking, and each <mask> was better than the last.\"\n",
    "s3 = \"soup by soup the chef improved his cooking, and each <mask> was better than the last.\"\n",
    "s3 = \"On our backpacking trip, we made the trip eating sandwich by sandwich.\"\n",
    "s3 = \"The journey was long but sandwich by sandwich we ate our way through it.\"\n",
    "s3 = \"We moved from <mask> to <mask>, tasting a variety of delicious fillings.\"\n",
    "s3 = \"We moved from sandwich to sandwich.\"\n",
    "s3 = \"We moved from sandwich to sandwich, tasting a variety of delicious fillings.\"\n",
    "s3 = \"In the prison, the inmates were watched guard by guard to ensure maximum security.\"\n",
    "s3 = \"In the prison system, the inmates were kept under strict surveillance, with guard upon guard watching their every move.\"\n",
    "s3 = \"He found himself stuck in a cycle, <mask> after <mask>, unable to break free from his unhealthy habits.\"\n",
    "s3 = \"The older boys help the younger ones.\"\n",
    "s3 = \"The older you are, the weaker you get.\"\n",
    "s3 = \"I was so certain \"\n",
    "s3 = \"Alice went to the hardware store and she bought a hammer.\"\n",
    "plot_all_affinities(s3, use_euclid=False, num_preds=5)\n"
   ],
   "id": "adec273363672318"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7ae16964886702a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e55485e1c6a134ee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
